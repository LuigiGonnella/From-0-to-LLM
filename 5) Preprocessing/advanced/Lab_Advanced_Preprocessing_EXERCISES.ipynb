{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b16795e3",
   "metadata": {},
   "source": [
    "# üéØ Advanced Preprocessing - Esercizi Pratici\n",
    "\n",
    "## üìã Obiettivi\n",
    "Questa serie di esercizi ti guider√† attraverso la creazione di pipeline di preprocessing avanzate per progetti ML professionali.\n",
    "\n",
    "### üéì Cosa Imparerai\n",
    "- Costruire pipeline automatizzate con `Pipeline` e `ColumnTransformer`\n",
    "- Implementare strategie di rilevamento e trattamento degli outlier\n",
    "- Valutare pipeline con cross-validation\n",
    "- Analizzare l'importanza delle features\n",
    "- Tracciare esperimenti con MLflow\n",
    "- Salvare e versionare modelli per la produzione\n",
    "\n",
    "### üìä Dataset\n",
    "Useremo il dataset **Wine Quality** per predire la qualit√† del vino basandoci su caratteristiche chimiche.\n",
    "\n",
    "### ‚ö†Ô∏è Importante\n",
    "- Segui l'ordine degli esercizi\n",
    "- Testa il tuo codice dopo ogni sezione\n",
    "- Non guardare la soluzione fino a quando non hai provato!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbe0213",
   "metadata": {},
   "source": [
    "## üì¶ Esercizio 1: Import e Setup\n",
    "\n",
    "**Obiettivo**: Importare tutte le librerie necessarie per il preprocessing avanzato.\n",
    "\n",
    "**Istruzioni**:\n",
    "1. Importa le librerie base: `pandas`, `numpy`, `matplotlib.pyplot`, `seaborn`\n",
    "2. Importa da sklearn:\n",
    "   - `train_test_split`, `cross_val_score`, `StratifiedKFold`\n",
    "   - `Pipeline`, `ColumnTransformer`\n",
    "   - `StandardScaler`, `MinMaxScaler`, `OneHotEncoder`, `OrdinalEncoder`\n",
    "   - `SimpleImputer`, `KNNImputer`\n",
    "   - `SelectKBest`, `f_classif`, `RFE`\n",
    "   - `IsolationForest` da `sklearn.ensemble`\n",
    "   - `RandomForestClassifier`, `LogisticRegression`\n",
    "   - `classification_report`, `confusion_matrix`, `roc_auc_score`\n",
    "3. Importa `stats` da `scipy`\n",
    "4. Prova a importare `mlflow` (opzionale)\n",
    "5. Importa `joblib`, `datetime`, `os`, `json`\n",
    "6. Configura pandas per mostrare tutte le colonne\n",
    "7. Stampa un messaggio di conferma\n",
    "\n",
    "**Tips**:\n",
    "- Usa `warnings.filterwarnings('ignore')` per nascondere i warning\n",
    "- Imposta `plt.style.use('seaborn-v0_8')` per grafici pi√π belli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0e9902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IL TUO CODICE QUI\n",
    "# Importa tutte le librerie necessarie\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e59ca09",
   "metadata": {},
   "source": [
    "## üìä Esercizio 2: Caricamento e Esplorazione Dati\n",
    "\n",
    "**Obiettivo**: Caricare il dataset Wine Quality e fare un'analisi esplorativa.\n",
    "\n",
    "**Istruzioni**:\n",
    "1. Carica il dataset da: `https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv`\n",
    "2. Il separatore √® `;` \n",
    "3. Crea la variabile target: `y = (data['quality'] >= 7).astype(int)` (1 = vino di alta qualit√†)\n",
    "4. Rimuovi la colonna 'quality' da X\n",
    "5. Esplora il dataset:\n",
    "   - Forma del dataset\n",
    "   - Informazioni sui tipi di dati\n",
    "   - Distribuzione del target\n",
    "   - Statistiche descrittive\n",
    "   - Valori mancanti\n",
    "6. Crea un grafico della distribuzione del target\n",
    "\n",
    "**Tips**:\n",
    "- Usa `pd.read_csv()` con il parametro `sep=';'`\n",
    "- Usa `.info()`, `.describe()`, `.isnull().sum()` per l'esplorazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9397f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IL TUO CODICE QUI\n",
    "# Carica e esplora il dataset Wine Quality\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a568f4",
   "metadata": {},
   "source": [
    "## üîß Esercizio 3: Identificazione delle Features\n",
    "\n",
    "**Obiettivo**: Automatizzare l'identificazione dei tipi di feature.\n",
    "\n",
    "**Istruzioni**:\n",
    "1. Crea una funzione `identify_feature_types(df)` che:\n",
    "   - Identifica le features numeriche usando `select_dtypes(include=[np.number])`\n",
    "   - Identifica le features categoriche usando `select_dtypes(include=['object', 'category'])`\n",
    "   - Ritorna due liste: `numerical_features`, `categorical_features`\n",
    "2. Applica la funzione al tuo dataset\n",
    "3. Stampa:\n",
    "   - Numero e nomi delle features numeriche\n",
    "   - Numero e nomi delle features categoriche\n",
    "4. Verifica se ci sono valori mancanti per ogni tipo di feature\n",
    "\n",
    "**Tips**:\n",
    "- Nel dataset Wine Quality tutte le features dovrebbero essere numeriche\n",
    "- Se non ci sono features categoriche, la lista sar√† vuota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebd3d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IL TUO CODICE QUI\n",
    "# Crea la funzione per identificare i tipi di feature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159118d4",
   "metadata": {},
   "source": [
    "## üîç Esercizio 4: Rilevamento Outlier\n",
    "\n",
    "**Obiettivo**: Implementare diversi metodi per rilevare outlier.\n",
    "\n",
    "**Istruzioni**:\n",
    "1. Crea una funzione `detect_outliers(X, method='iqr', contamination=0.1)` che:\n",
    "   - Metodo 'iqr': Usa Q1, Q3 e IQR per trovare outlier (limite: Q1-1.5*IQR, Q3+1.5*IQR)\n",
    "   - Metodo 'zscore': Usa z-score > 3 come soglia\n",
    "   - Metodo 'isolation_forest': Usa IsolationForest con contamination specificata\n",
    "   - Ritorna una maschera booleana (True = outlier)\n",
    "\n",
    "2. Testa tutti e tre i metodi sui tuoi dati\n",
    "3. Stampa per ogni metodo:\n",
    "   - Numero di outlier trovati\n",
    "   - Percentuale di outlier\n",
    "\n",
    "4. Crea una visualizzazione che mostri gli outlier per una feature a tua scelta usando tutti e tre i metodi\n",
    "\n",
    "**Tips**:\n",
    "- Usa `np.percentile()` per Q1 e Q3\n",
    "- Usa `stats.zscore()` per il z-score\n",
    "- Usa `.any(axis=1)` per trovare righe con almeno un outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25acbb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IL TUO CODICE QUI\n",
    "# Implementa la funzione per il rilevamento degli outlier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d3feb9",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Esercizio 5: Pipeline di Preprocessing\n",
    "\n",
    "**Obiettivo**: Creare pipeline automatizzate per preprocessing.\n",
    "\n",
    "**Istruzioni**:\n",
    "1. Crea una pipeline per features numeriche:\n",
    "   - Imputation con `KNNImputer(n_neighbors=5)`\n",
    "   - Scaling con `StandardScaler()`\n",
    "\n",
    "2. Crea una pipeline per features categoriche (se esistono):\n",
    "   - Imputation con `SimpleImputer(strategy='most_frequent')`\n",
    "   - Encoding con `OneHotEncoder(drop='first', handle_unknown='ignore')`\n",
    "\n",
    "3. Combina le pipeline usando `ColumnTransformer`:\n",
    "   - Assegna la pipeline numerica alle features numeriche\n",
    "   - Assegna la pipeline categorica alle features categoriche\n",
    "   - Usa `remainder='drop'`\n",
    "\n",
    "4. Dividi i dati in train/test (80/20) con stratificazione\n",
    "5. Applica il preprocessor ai dati e stampa:\n",
    "   - Forma originale vs forma processata\n",
    "   - Numero di features create\n",
    "\n",
    "**Tips**:\n",
    "- Usa `stratify=y` in `train_test_split`\n",
    "- Usa `.fit_transform()` per train e `.transform()` per test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62914624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IL TUO CODICE QUI\n",
    "# Crea le pipeline di preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5e152a",
   "metadata": {},
   "source": [
    "## üéØ Esercizio 6: Trattamento Outlier\n",
    "\n",
    "**Obiettivo**: Implementare strategie per trattare gli outlier.\n",
    "\n",
    "**Istruzioni**:\n",
    "1. Crea una classe `OutlierTreatmentTransformer` che:\n",
    "   - Ha parametri `method='cap'` e `detection_method='iqr'`\n",
    "   - Nel metodo `fit()`: calcola e salva i bounds per il capping\n",
    "   - Nel metodo `transform()`: applica il trattamento scelto\n",
    "   - Supporta il metodo 'cap' (taglia i valori ai bounds)\n",
    "\n",
    "2. Integra il transformer nella tua pipeline completa\n",
    "3. Crea una funzione `create_complete_pipeline(model, include_outlier_treatment=True)` che:\n",
    "   - Combina outlier treatment + preprocessing + modello\n",
    "   - Permette di includere/escludere il trattamento outlier\n",
    "\n",
    "4. Testa la pipeline con `RandomForestClassifier`\n",
    "\n",
    "**Tips**:\n",
    "- Usa `np.clip()` per il capping\n",
    "- Salva i bounds in un dizionario durante il fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885d91ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IL TUO CODICE QUI\n",
    "# Implementa il trattamento degli outlier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446545dd",
   "metadata": {},
   "source": [
    "## üìä Esercizio 7: Cross-Validation\n",
    "\n",
    "**Obiettivo**: Valutare le pipeline con cross-validation.\n",
    "\n",
    "**Istruzioni**:\n",
    "1. Definisci una strategia di CV: `StratifiedKFold(n_splits=5, shuffle=True, random_state=42)`\n",
    "2. Testa diverse combinazioni:\n",
    "   - LogisticRegression con/senza outlier treatment\n",
    "   - RandomForestClassifier con/senza outlier treatment\n",
    "3. Per ogni combinazione:\n",
    "   - Esegui cross-validation con scoring='roc_auc'\n",
    "   - Calcola media, deviazione standard, min, max degli score\n",
    "   - Salva i risultati in un dizionario\n",
    "4. Crea un boxplot per visualizzare i risultati CV\n",
    "5. Identifica la migliore configurazione\n",
    "\n",
    "**Tips**:\n",
    "- Usa `cross_val_score()` con `n_jobs=-1` per parallelizzazione\n",
    "- Usa `plt.boxplot()` per la visualizzazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a3d81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IL TUO CODICE QUI\n",
    "# Implementa la cross-validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ef2d1d",
   "metadata": {},
   "source": [
    "## üéØ Esercizio 8: Feature Importance\n",
    "\n",
    "**Obiettivo**: Analizzare l'importanza delle features.\n",
    "\n",
    "**Istruzioni**:\n",
    "1. Addestra la migliore pipeline sui dati di training\n",
    "2. Estrai i nomi delle features dopo il preprocessing:\n",
    "   - Features numeriche: nomi originali\n",
    "   - Features categoriche: usa `get_feature_names_out()` dell'encoder\n",
    "3. Calcola due tipi di importanza:\n",
    "   - Tree-based importance: `model.feature_importances_`\n",
    "   - Permutation importance: usa `permutation_importance()`\n",
    "4. Crea un DataFrame con feature names e importanze\n",
    "5. Visualizza i risultati:\n",
    "   - Top 15 features per tree-based importance\n",
    "   - Top 15 features per permutation importance (con error bars)\n",
    "6. Identifica features con bassa importanza (< 0.001) per possibile rimozione\n",
    "\n",
    "**Tips**:\n",
    "- Usa `permutation_importance(..., n_repeats=10, n_jobs=-1)`\n",
    "- Usa `plt.barh()` per grafici orizzontali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d588b067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IL TUO CODICE QUI\n",
    "# Analizza l'importanza delle features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a4b550",
   "metadata": {},
   "source": [
    "## üìà Esercizio 9: MLflow Experiment Tracking (Opzionale)\n",
    "\n",
    "**Obiettivo**: Tracciare esperimenti con MLflow.\n",
    "\n",
    "**Istruzioni** (solo se hai installato MLflow):\n",
    "1. Configura un esperimento MLflow: `mlflow.set_experiment(\"Wine_Quality_Advanced\")`\n",
    "2. Crea una funzione `log_experiment()` che:\n",
    "   - Inizia un run MLflow\n",
    "   - Logga parametri del modello e preprocessing\n",
    "   - Addestra la pipeline\n",
    "   - Calcola metriche (train/test AUC)\n",
    "   - Logga metriche e modello\n",
    "3. Esegui esperimenti per diverse configurazioni\n",
    "4. Confronta i risultati\n",
    "5. Salva il modello migliore\n",
    "\n",
    "**Se non hai MLflow**:\n",
    "- Salta questo esercizio\n",
    "- Vai direttamente all'esercizio 10\n",
    "\n",
    "**Tips**:\n",
    "- Usa `mlflow.start_run()` come context manager\n",
    "- Usa `mlflow.sklearn.log_model()` per salvare il modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6134f41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IL TUO CODICE QUI (OPZIONALE)\n",
    "# Implementa MLflow experiment tracking\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29a88b6",
   "metadata": {},
   "source": [
    "## üíæ Esercizio 10: Salvataggio e Versionamento\n",
    "\n",
    "**Obiettivo**: Salvare la pipeline per la produzione.\n",
    "\n",
    "**Istruzioni**:\n",
    "1. Crea una directory `models/`\n",
    "2. Addestra la migliore pipeline sui dati completi\n",
    "3. Crea un dizionario `model_metadata` con:\n",
    "   - Tipo di modello e parametri\n",
    "   - Features utilizzate\n",
    "   - Step di preprocessing\n",
    "   - Performance (train/test AUC)\n",
    "   - Timestamp di creazione\n",
    "   - Nomi delle features dopo preprocessing\n",
    "4. Salva pipeline e metadata con timestamp nel nome:\n",
    "   - Pipeline: `wine_pipeline_v{timestamp}.joblib`\n",
    "   - Metadata: `wine_metadata_v{timestamp}.json`\n",
    "5. Crea una funzione `predict_wine_quality()` che:\n",
    "   - Carica pipeline e metadata\n",
    "   - Prende input nuovo vino\n",
    "   - Ritorna predizione con probabilit√†\n",
    "6. Testa la funzione con un esempio\n",
    "\n",
    "**Tips**:\n",
    "- Usa `datetime.now().strftime(\"%Y%m%d_%H%M%S\")` per timestamp\n",
    "- Usa `joblib.dump()` e `json.dump()` per salvare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4186e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IL TUO CODICE QUI\n",
    "# Implementa il salvataggio e versionamento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb1dc2a",
   "metadata": {},
   "source": [
    "## üéâ Esercizio 11: Sfida Finale\n",
    "\n",
    "**Obiettivo**: Metti tutto insieme in una pipeline completa.\n",
    "\n",
    "**Istruzioni**:\n",
    "1. Crea una funzione `build_complete_ml_pipeline()` che:\n",
    "   - Prende in input un dataset\n",
    "   - Identifica automaticamente i tipi di feature\n",
    "   - Crea preprocessing pipeline ottimale\n",
    "   - Testa diversi modelli con CV\n",
    "   - Seleziona il migliore\n",
    "   - Salva tutto con metadata completo\n",
    "   - Ritorna la pipeline addestrata e le performance\n",
    "\n",
    "2. Testa la funzione sul dataset Wine Quality\n",
    "3. **Bonus**: Prova la funzione su un altro dataset (es. Iris, Boston Housing)\n",
    "\n",
    "**Valutazione**:\n",
    "- La funzione deve essere completamente automatizzata\n",
    "- Deve gestire sia features numeriche che categoriche\n",
    "- Deve produrre risultati riproducibili\n",
    "- Deve essere pronta per la produzione\n",
    "\n",
    "**Tips**:\n",
    "- Usa tutto quello che hai imparato negli esercizi precedenti\n",
    "- Fai una funzione modulare e riutilizzabile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c063978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IL TUO CODICE QUI - SFIDA FINALE\n",
    "# Crea la pipeline ML completa e automatizzata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e064a317",
   "metadata": {},
   "source": [
    "## üèÜ Congratulazioni!\n",
    "\n",
    "Se hai completato tutti gli esercizi, ora hai le competenze per:\n",
    "\n",
    "‚úÖ **Creare pipeline automatizzate** per preprocessing professionale  \n",
    "‚úÖ **Gestire outlier** con strategie appropriate  \n",
    "‚úÖ **Valutare modelli** con cross-validation robusta  \n",
    "‚úÖ **Analizzare feature importance** per interpretabilit√†  \n",
    "‚úÖ **Tracciare esperimenti** per riproducibilit√†  \n",
    "‚úÖ **Versionare modelli** per deployment produzione  \n",
    "\n",
    "### üöÄ Prossimi Passi\n",
    "1. Prova la tua pipeline su altri dataset\n",
    "2. Implementa hyperparameter tuning automatico\n",
    "3. Aggiungi data validation con Great Expectations\n",
    "4. Crea un'API REST per servire il modello\n",
    "5. Configura monitoring per production\n",
    "\n",
    "### üìö Risorse Aggiuntive\n",
    "- [Scikit-learn Pipeline Guide](https://scikit-learn.org/stable/modules/compose.html)\n",
    "- [MLflow Documentation](https://mlflow.org/docs/latest/)\n",
    "- [Production ML Best Practices](https://ml-ops.org/)\n",
    "\n",
    "**üéØ Hai costruito una base solida per ML Engineering professionale!**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
