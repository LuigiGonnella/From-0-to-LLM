{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c786c38",
   "metadata": {},
   "source": [
    "# Advanced Preprocessing & MLOps for Tabular Data\n",
    "\n",
    "## üöÄ Professional-Level Data Preprocessing Pipeline\n",
    "\n",
    "This notebook builds upon the basic preprocessing techniques to introduce **production-ready** data preprocessing workflows using advanced Scikit-Learn features and MLOps best practices.\n",
    "\n",
    "### üéØ What You'll Learn\n",
    "- **Automated Pipelines** with `Pipeline` and `ColumnTransformer`\n",
    "- **Outlier Detection** and treatment strategies\n",
    "- **Cross-Validation** for preprocessing and model evaluation\n",
    "- **Feature Importance** analysis and selection\n",
    "- **MLflow** experiment tracking and versioning\n",
    "- **Pipeline Persistence** for production deployment\n",
    "\n",
    "### üìä Dataset\n",
    "We'll use the same **Titanic dataset** to demonstrate how these advanced techniques improve upon basic preprocessing approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ec6cd4",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries and Setup\n",
    "\n",
    "Let's import all the libraries we'll need for advanced preprocessing and MLOps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9005f4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Scikit-learn core\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Advanced preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFE\n",
    "\n",
    "# Outlier detection\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from scipy import stats\n",
    "\n",
    "# Models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Feature importance\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# MLflow for experiment tracking\n",
    "try:\n",
    "    import mlflow\n",
    "    import mlflow.sklearn\n",
    "    MLFLOW_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è MLflow not installed. Run: pip install mlflow\")\n",
    "    MLFLOW_AVAILABLE = False\n",
    "\n",
    "# Model persistence\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d6bffe",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare Data\n",
    "\n",
    "We'll load the Titanic dataset and perform initial exploration to understand our preprocessing needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f0395d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Titanic dataset\n",
    "print(\"üì• Loading Titanic dataset...\")\n",
    "X, y = fetch_openml('titanic', version=1, as_frame=True, parser='auto', return_X_y=True)\n",
    "\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"Target distribution:\\n{y.value_counts()}\")\n",
    "\n",
    "# Initial data exploration\n",
    "print(\"\\nüìä Data Overview:\")\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd77e382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify feature types for automated preprocessing\n",
    "def identify_feature_types(df):\n",
    "    \"\"\"\n",
    "    Automatically identify numerical and categorical features.\n",
    "    \"\"\"\n",
    "    numerical_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    categorical_features = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    # Remove features that shouldn't be used for prediction\n",
    "    features_to_remove = ['boat', 'body', 'home.dest', 'name', 'ticket']\n",
    "    numerical_features = [f for f in numerical_features if f not in features_to_remove]\n",
    "    categorical_features = [f for f in categorical_features if f not in features_to_remove]\n",
    "    \n",
    "    return numerical_features, categorical_features\n",
    "\n",
    "numerical_features, categorical_features = identify_feature_types(X)\n",
    "\n",
    "print(f\"üìä Numerical features ({len(numerical_features)}): {numerical_features}\")\n",
    "print(f\"üìù Categorical features ({len(categorical_features)}): {categorical_features}\")\n",
    "\n",
    "# Check missing values\n",
    "missing_summary = X[numerical_features + categorical_features].isnull().sum()\n",
    "missing_summary = missing_summary[missing_summary > 0].sort_values(ascending=False)\n",
    "print(f\"\\n‚ùå Missing values:\")\n",
    "for feature, count in missing_summary.items():\n",
    "    percentage = (count / len(X)) * 100\n",
    "    print(f\"  {feature}: {count} ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791337cd",
   "metadata": {},
   "source": [
    "## 3. Create Preprocessing Pipelines with ColumnTransformer\n",
    "\n",
    "We'll create automated, reproducible preprocessing pipelines that handle numerical and categorical features separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e48cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing pipelines for different feature types\n",
    "\n",
    "# Numerical preprocessing pipeline\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('imputer', KNNImputer(n_neighbors=5)),  # More sophisticated imputation\n",
    "    ('scaler', StandardScaler())  # Standardization\n",
    "])\n",
    "\n",
    "# Categorical preprocessing pipeline\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(drop='first', handle_unknown='ignore'))  # Avoid dummy variable trap\n",
    "])\n",
    "\n",
    "# Combine pipelines using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numerical', numerical_pipeline, numerical_features),\n",
    "        ('categorical', categorical_pipeline, categorical_features)\n",
    "    ],\n",
    "    remainder='drop'  # Drop any remaining columns\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Preprocessing pipeline created!\")\n",
    "print(f\"üìä Pipeline structure:\")\n",
    "print(f\"  - Numerical features: {len(numerical_features)} ‚Üí KNN Imputation + Standardization\")\n",
    "print(f\"  - Categorical features: {len(categorical_features)} ‚Üí Mode Imputation + One-Hot Encoding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6b5998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for pipeline evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"üìä Data split:\")\n",
    "print(f\"  - Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"  - Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"  - Training target distribution: {y_train.value_counts().to_dict()}\")\n",
    "print(f\"  - Test target distribution: {y_test.value_counts().to_dict()}\")\n",
    "\n",
    "# Apply preprocessing pipeline\n",
    "print(\"\\nüîÑ Applying preprocessing pipeline...\")\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)  # Only transform, don't refit!\n",
    "\n",
    "print(f\"‚úÖ Preprocessing completed!\")\n",
    "print(f\"  - Original features: {X_train.shape[1]}\")\n",
    "print(f\"  - Processed features: {X_train_processed.shape[1]}\")\n",
    "print(f\"  - Feature reduction: {X_train.shape[1] - X_train_processed.shape[1]} features removed/combined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db5917d",
   "metadata": {},
   "source": [
    "## 4. Outlier Detection and Treatment\n",
    "\n",
    "Let's implement various outlier detection methods and treatment strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3abd454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect outliers using different methods\n",
    "def detect_outliers(X, method='iqr', contamination=0.1):\n",
    "    \"\"\"\n",
    "    Detect outliers using various methods.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : array-like\n",
    "        Input data\n",
    "    method : str\n",
    "        Method to use: 'iqr', 'zscore', 'isolation_forest'\n",
    "    contamination : float\n",
    "        Expected proportion of outliers (for isolation forest)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    outlier_mask : array\n",
    "        Boolean mask indicating outliers (True = outlier)\n",
    "    \"\"\"\n",
    "    if method == 'iqr':\n",
    "        Q1 = np.percentile(X, 25, axis=0)\n",
    "        Q3 = np.percentile(X, 75, axis=0)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        outlier_mask = (X < lower_bound).any(axis=1) | (X > upper_bound).any(axis=1) #prima realizza matrice boolean in cui, per ogni feature indica se quel valore e un outlier o no e poi (con .any e azione sulle colonne) \n",
    "        #crea un array di boolean in cui True=riga con almeno un outlier in qualche feature e False viceversa\n",
    "        \n",
    "    elif method == 'zscore':\n",
    "        z_scores = np.abs(stats.zscore(X, axis=0, nan_policy='omit'))\n",
    "        outlier_mask = (z_scores > 3).any(axis=1)\n",
    "        \n",
    "    elif method == 'isolation_forest':\n",
    "        iso_forest = IsolationForest(contamination=contamination, random_state=42)\n",
    "        outlier_predictions = iso_forest.fit_predict(X)\n",
    "        outlier_mask = outlier_predictions == -1\n",
    "    \n",
    "    return outlier_mask\n",
    "\n",
    "# Apply outlier detection on numerical features only\n",
    "X_train_numeric = X_train[numerical_features].fillna(X_train[numerical_features].median())\n",
    "\n",
    "methods = ['iqr', 'zscore', 'isolation_forest']\n",
    "outlier_results = {}\n",
    "\n",
    "print(\"üîç Outlier Detection Results:\")\n",
    "for method in methods:\n",
    "    outliers = detect_outliers(X_train_numeric.values, method=method)\n",
    "    outlier_results[method] = outliers\n",
    "    n_outliers = np.sum(outliers)\n",
    "    percentage = (n_outliers / len(X_train)) * 100\n",
    "    print(f\"  {method.upper()}: {n_outliers} outliers ({percentage:.1f}%)\")\n",
    "\n",
    "# Visualize outliers for fare (most likely to have outliers)\n",
    "if 'fare' in numerical_features:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    for i, method in enumerate(methods):\n",
    "        outliers = outlier_results[method]\n",
    "        axes[i].scatter(X_train_numeric.index[~outliers], X_train_numeric.loc[~outliers, 'fare'], \n",
    "                       alpha=0.6, label='Normal', s=20)\n",
    "        axes[i].scatter(X_train_numeric.index[outliers], X_train_numeric.loc[outliers, 'fare'], \n",
    "                       alpha=0.8, label='Outlier', s=20, color='red')\n",
    "        axes[i].set_title(f'Outliers: {method.upper()}')\n",
    "        axes[i].set_ylabel('Fare')\n",
    "        axes[i].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebc9a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier treatment strategies\n",
    "def treat_outliers(X, outlier_mask, method='remove'):\n",
    "    \"\"\"\n",
    "    Treat outliers using various strategies.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : DataFrame\n",
    "        Input data\n",
    "    outlier_mask : array\n",
    "        Boolean mask indicating outliers\n",
    "    method : str\n",
    "        Treatment method: 'remove', 'cap', 'log_transform'\n",
    "    \"\"\"\n",
    "    X_treated = X.copy()\n",
    "    \n",
    "    if method == 'remove':\n",
    "        return X_treated[~outlier_mask]\n",
    "    \n",
    "    elif method == 'cap':\n",
    "        for col in X_treated.select_dtypes(include=[np.number]).columns:\n",
    "            Q1 = X_treated[col].quantile(0.25)\n",
    "            Q3 = X_treated[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            \n",
    "            X_treated[col] = np.clip(X_treated[col], lower_bound, upper_bound)\n",
    "    \n",
    "    elif method == 'log_transform':\n",
    "        for col in X_treated.select_dtypes(include=[np.number]).columns:\n",
    "            if (X_treated[col] > 0).all():  # Only apply to positive values\n",
    "                X_treated[col] = np.log1p(X_treated[col])\n",
    "    \n",
    "    return X_treated\n",
    "\n",
    "# Example: Create preprocessor with outlier treatment\n",
    "class OutlierTreatmentTransformer:\n",
    "    def __init__(self, method='cap', detection_method='iqr'):\n",
    "        self.method = method\n",
    "        self.detection_method = detection_method\n",
    "        self.bounds_ = {}\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # Store bounds for capping during training\n",
    "        if self.method == 'cap':\n",
    "            for col in X.select_dtypes(include=[np.number]).columns:\n",
    "                Q1 = X[col].quantile(0.25)\n",
    "                Q3 = X[col].quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "                self.bounds_[col] = {\n",
    "                    'lower': Q1 - 1.5 * IQR,\n",
    "                    'upper': Q3 + 1.5 * IQR\n",
    "                }\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_transformed = X.copy()\n",
    "        \n",
    "        if self.method == 'cap':\n",
    "            for col, bounds in self.bounds_.items():\n",
    "                if col in X_transformed.columns:\n",
    "                    X_transformed[col] = np.clip(\n",
    "                        X_transformed[col], \n",
    "                        bounds['lower'], \n",
    "                        bounds['upper']\n",
    "                    )\n",
    "        \n",
    "        return X_transformed\n",
    "\n",
    "print(\"‚úÖ Outlier treatment methods implemented!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019cb575",
   "metadata": {},
   "source": [
    "## 5. Cross-Validation and Pipeline Evaluation\n",
    "\n",
    "Let's implement comprehensive cross-validation strategies for our preprocessing pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abe9ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create complete pipeline with model\n",
    "def create_complete_pipeline(model, include_outlier_treatment=True):\n",
    "    \"\"\"\n",
    "    Create a complete preprocessing + modeling pipeline.\n",
    "    \"\"\"\n",
    "    steps = []\n",
    "    \n",
    "    # Add outlier treatment if requested\n",
    "    if include_outlier_treatment:\n",
    "        steps.append(('outlier_treatment', OutlierTreatmentTransformer(method='cap')))\n",
    "    \n",
    "    # Add preprocessing\n",
    "    steps.append(('preprocessor', preprocessor))\n",
    "    \n",
    "    # Add model\n",
    "    steps.append(('model', model))\n",
    "    \n",
    "    return Pipeline(steps)\n",
    "\n",
    "# Define models to compare\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "}\n",
    "\n",
    "# Cross-validation evaluation\n",
    "cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_results = {}\n",
    "\n",
    "print(\"üîÑ Running cross-validation evaluation...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nüìä Evaluating {model_name}:\")\n",
    "    \n",
    "    # Test with and without outlier treatment\n",
    "    for outlier_treatment in [False, True]:\n",
    "        pipeline = create_complete_pipeline(model, include_outlier_treatment=outlier_treatment)\n",
    "        \n",
    "        # Perform cross-validation\n",
    "        cv_scores = cross_val_score(\n",
    "            pipeline, X_train, y_train, \n",
    "            cv=cv_strategy, \n",
    "            scoring='roc_auc',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        treatment_label = \"with outlier treatment\" if outlier_treatment else \"without outlier treatment\"\n",
    "        result_key = f\"{model_name}_{treatment_label}\"\n",
    "        cv_results[result_key] = cv_scores\n",
    "        \n",
    "        print(f\"  {treatment_label}:\")\n",
    "        print(f\"    Mean CV Score: {cv_scores.mean():.4f} (¬±{cv_scores.std():.4f})\")\n",
    "        print(f\"    Score Range: [{cv_scores.min():.4f}, {cv_scores.max():.4f}]\")\n",
    "\n",
    "# Visualize CV results\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "positions = range(len(cv_results))\n",
    "box_data = list(cv_results.values())\n",
    "labels = list(cv_results.keys())\n",
    "\n",
    "bp = ax.boxplot(box_data, positions=positions, patch_artist=True)\n",
    "ax.set_xticklabels([label.replace('_', '\\n') for label in labels], rotation=45, ha='right')\n",
    "ax.set_ylabel('ROC-AUC Score')\n",
    "ax.set_title('Cross-Validation Results: Pipeline Comparison')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Color boxes\n",
    "colors = ['lightblue', 'lightcoral', 'lightgreen', 'lightyellow']\n",
    "for patch, color in zip(bp['boxes'], colors[:len(bp['boxes'])]):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c420ba",
   "metadata": {},
   "source": [
    "## 6. Feature Importance Analysis\n",
    "\n",
    "Let's analyze which features and preprocessing steps contribute most to model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0045f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train best pipeline and analyze feature importance\n",
    "best_pipeline = create_complete_pipeline(\n",
    "    RandomForestClassifier(random_state=42, n_estimators=100), \n",
    "    include_outlier_treatment=True\n",
    ")\n",
    "\n",
    "# Fit the pipeline\n",
    "print(\"üîÑ Training best pipeline for feature importance analysis...\")\n",
    "best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Get feature names after preprocessing\n",
    "def get_feature_names(pipeline):\n",
    "    \"\"\"\n",
    "    Extract feature names from a preprocessing pipeline.\n",
    "    \"\"\"\n",
    "    preprocessor = pipeline.named_steps['preprocessor']\n",
    "    \n",
    "    # Get numerical feature names\n",
    "    num_features = numerical_features\n",
    "    \n",
    "    # Get categorical feature names\n",
    "    cat_transformer = preprocessor.named_transformers_['categorical']\n",
    "    cat_encoder = cat_transformer.named_steps['encoder']\n",
    "    cat_features = cat_encoder.get_feature_names_out(categorical_features)\n",
    "    \n",
    "    return list(num_features) + list(cat_features)\n",
    "\n",
    "feature_names = get_feature_names(best_pipeline)\n",
    "print(f\"üìä Total features after preprocessing: {len(feature_names)}\")\n",
    "\n",
    "# 1. Tree-based feature importance\n",
    "model = best_pipeline.named_steps['model']\n",
    "tree_importance = model.feature_importances_\n",
    "\n",
    "# 2. Permutation importance\n",
    "print(\"üîÑ Calculating permutation importance...\")\n",
    "perm_importance = permutation_importance(\n",
    "    best_pipeline, X_test, y_test, \n",
    "    n_repeats=10, random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "# Create importance DataFrame\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'tree_importance': tree_importance,\n",
    "    'perm_importance_mean': perm_importance.importances_mean,\n",
    "    'perm_importance_std': perm_importance.importances_std\n",
    "})\n",
    "\n",
    "# Sort by permutation importance\n",
    "importance_df = importance_df.sort_values('perm_importance_mean', ascending=False)\n",
    "\n",
    "print(\"\\nüéØ Top 10 Most Important Features:\")\n",
    "print(importance_df.head(10).to_string(index=False, float_format='%.4f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6e6cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# Tree-based importance\n",
    "top_features_tree = importance_df.nlargest(15, 'tree_importance')\n",
    "axes[0].barh(range(len(top_features_tree)), top_features_tree['tree_importance'])\n",
    "axes[0].set_yticks(range(len(top_features_tree)))\n",
    "axes[0].set_yticklabels(top_features_tree['feature'])\n",
    "axes[0].set_xlabel('Importance')\n",
    "axes[0].set_title('Tree-based Feature Importance\\n(Random Forest)')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "# Permutation importance\n",
    "top_features_perm = importance_df.nlargest(15, 'perm_importance_mean')\n",
    "axes[1].barh(range(len(top_features_perm)), top_features_perm['perm_importance_mean'],\n",
    "            xerr=top_features_perm['perm_importance_std'])\n",
    "axes[1].set_yticks(range(len(top_features_perm)))\n",
    "axes[1].set_yticklabels(top_features_perm['feature'])\n",
    "axes[1].set_xlabel('Importance')\n",
    "axes[1].set_title('Permutation Feature Importance\\n(with error bars)')\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature selection based on importance\n",
    "print(\"\\nüéØ Feature Selection Recommendations:\")\n",
    "low_importance_features = importance_df[importance_df['perm_importance_mean'] < 0.001]['feature'].tolist()\n",
    "print(f\"üìâ Low importance features ({len(low_importance_features)}): {low_importance_features[:5]}...\")\n",
    "print(f\"üí° Consider removing these features to reduce model complexity.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39214178",
   "metadata": {},
   "source": [
    "## 7. MLflow Experiment Tracking\n",
    "\n",
    "Let's set up MLflow to track our experiments, parameters, and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c67855",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MLFLOW_AVAILABLE:\n",
    "    # Set up MLflow\n",
    "    mlflow.set_experiment(\"Titanic_Advanced_Preprocessing\")\n",
    "    \n",
    "    def log_experiment(pipeline, X_train, X_test, y_train, y_test, \n",
    "                      experiment_name, parameters=None):\n",
    "        \"\"\"\n",
    "        Log an experiment to MLflow.\n",
    "        \"\"\"\n",
    "        with mlflow.start_run(run_name=experiment_name):\n",
    "            # Log parameters\n",
    "            if parameters:\n",
    "                for key, value in parameters.items():\n",
    "                    mlflow.log_param(key, value)\n",
    "            \n",
    "            # Train pipeline\n",
    "            pipeline.fit(X_train, y_train)\n",
    "            \n",
    "            # Make predictions\n",
    "            train_predictions = pipeline.predict(X_train)\n",
    "            test_predictions = pipeline.predict(X_test)\n",
    "            train_proba = pipeline.predict_proba(X_train)[:, 1]\n",
    "            test_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "            \n",
    "            # Calculate metrics\n",
    "            train_auc = roc_auc_score(y_train, train_proba)\n",
    "            test_auc = roc_auc_score(y_test, test_proba)\n",
    "            \n",
    "            # Log metrics\n",
    "            mlflow.log_metric(\"train_auc\", train_auc)\n",
    "            mlflow.log_metric(\"test_auc\", test_auc)\n",
    "            mlflow.log_metric(\"overfitting\", train_auc - test_auc)\n",
    "            \n",
    "            # Log model\n",
    "            mlflow.sklearn.log_model(pipeline, \"model\")\n",
    "            \n",
    "            print(f\"‚úÖ Logged experiment: {experiment_name}\")\n",
    "            print(f\"   Train AUC: {train_auc:.4f}\")\n",
    "            print(f\"   Test AUC: {test_auc:.4f}\")\n",
    "            print(f\"   Overfitting: {train_auc - test_auc:.4f}\")\n",
    "            \n",
    "            return {\n",
    "                'train_auc': train_auc,\n",
    "                'test_auc': test_auc,\n",
    "                'pipeline': pipeline\n",
    "            }\n",
    "    \n",
    "    # Run experiments\n",
    "    print(\"üîÑ Running MLflow experiments...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    experiments = [\n",
    "        {\n",
    "            'name': 'Baseline_LogisticRegression',\n",
    "            'pipeline': create_complete_pipeline(\n",
    "                LogisticRegression(random_state=42, max_iter=1000),\n",
    "                include_outlier_treatment=False\n",
    "            ),\n",
    "            'params': {\n",
    "                'model_type': 'LogisticRegression',\n",
    "                'outlier_treatment': False,\n",
    "                'numerical_imputation': 'KNN',\n",
    "                'categorical_imputation': 'mode',\n",
    "                'scaling': 'StandardScaler'\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'name': 'Enhanced_LogisticRegression',\n",
    "            'pipeline': create_complete_pipeline(\n",
    "                LogisticRegression(random_state=42, max_iter=1000),\n",
    "                include_outlier_treatment=True\n",
    "            ),\n",
    "            'params': {\n",
    "                'model_type': 'LogisticRegression',\n",
    "                'outlier_treatment': True,\n",
    "                'numerical_imputation': 'KNN',\n",
    "                'categorical_imputation': 'mode',\n",
    "                'scaling': 'StandardScaler'\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'name': 'Enhanced_RandomForest',\n",
    "            'pipeline': create_complete_pipeline(\n",
    "                RandomForestClassifier(random_state=42, n_estimators=100),\n",
    "                include_outlier_treatment=True\n",
    "            ),\n",
    "            'params': {\n",
    "                'model_type': 'RandomForest',\n",
    "                'outlier_treatment': True,\n",
    "                'numerical_imputation': 'KNN',\n",
    "                'categorical_imputation': 'mode',\n",
    "                'n_estimators': 100\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    for exp in experiments:\n",
    "        result = log_experiment(\n",
    "            exp['pipeline'], X_train, X_test, y_train, y_test,\n",
    "            exp['name'], exp['params']\n",
    "        )\n",
    "        results.append({**result, 'name': exp['name']})\n",
    "        print()\n",
    "    \n",
    "    # Compare results\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df = results_df.sort_values('test_auc', ascending=False)\n",
    "    \n",
    "    print(\"\\nüèÜ Experiment Results Summary:\")\n",
    "    print(results_df[['name', 'train_auc', 'test_auc']].to_string(index=False, float_format='%.4f'))\n",
    "    \n",
    "    print(f\"\\nüí° Best model: {results_df.iloc[0]['name']} (Test AUC: {results_df.iloc[0]['test_auc']:.4f})\")\n",
    "    print(\"\\nüìä To view results in MLflow UI, run: mlflow ui\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è MLflow not available. Skipping experiment tracking.\")\n",
    "    print(\"   Install MLflow with: pip install mlflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097dd7be",
   "metadata": {},
   "source": [
    "## 8. Pipeline Persistence and Versioning\n",
    "\n",
    "Finally, let's save our best pipeline and demonstrate versioning for production deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3258776c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory for model artifacts\n",
    "model_dir = \"models\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Train and save the best pipeline\n",
    "print(\"üíæ Saving best pipeline...\")\n",
    "\n",
    "# Train the best pipeline\n",
    "best_pipeline = create_complete_pipeline(\n",
    "    RandomForestClassifier(random_state=42, n_estimators=100),\n",
    "    include_outlier_treatment=True\n",
    ")\n",
    "best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Create model metadata\n",
    "model_metadata = {\n",
    "    'model_type': 'RandomForest',\n",
    "    'n_estimators': 100,\n",
    "    'outlier_treatment': True,\n",
    "    'numerical_features': numerical_features,\n",
    "    'categorical_features': categorical_features,\n",
    "    'preprocessing_steps': [\n",
    "        'outlier_capping',\n",
    "        'knn_imputation_numerical',\n",
    "        'mode_imputation_categorical',\n",
    "        'standard_scaling',\n",
    "        'onehot_encoding'\n",
    "    ],\n",
    "    'train_auc': roc_auc_score(y_train, best_pipeline.predict_proba(X_train)[:, 1]),\n",
    "    'test_auc': roc_auc_score(y_test, best_pipeline.predict_proba(X_test)[:, 1]),\n",
    "    'created_at': datetime.now().isoformat(),\n",
    "    'feature_names': feature_names\n",
    "}\n",
    "\n",
    "# Save pipeline and metadata\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "model_filename = f\"titanic_pipeline_v{timestamp}.joblib\"\n",
    "metadata_filename = f\"titanic_metadata_v{timestamp}.json\"\n",
    "\n",
    "# Save the pipeline\n",
    "joblib.dump(best_pipeline, os.path.join(model_dir, model_filename))\n",
    "\n",
    "# Save metadata\n",
    "import json\n",
    "with open(os.path.join(model_dir, metadata_filename), 'w') as f:\n",
    "    json.dump(model_metadata, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Pipeline saved: {model_filename}\")\n",
    "print(f\"‚úÖ Metadata saved: {metadata_filename}\")\n",
    "print(f\"üìä Model performance: Train AUC={model_metadata['train_auc']:.4f}, Test AUC={model_metadata['test_auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f043380a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate loading and using the saved pipeline\n",
    "print(\"üîÑ Demonstrating model loading and inference...\")\n",
    "\n",
    "# Load the saved pipeline\n",
    "loaded_pipeline = joblib.load(os.path.join(model_dir, model_filename))\n",
    "\n",
    "# Load metadata\n",
    "with open(os.path.join(model_dir, metadata_filename), 'r') as f:\n",
    "    loaded_metadata = json.load(f)\n",
    "\n",
    "print(f\"üìã Loaded model metadata:\")\n",
    "for key, value in loaded_metadata.items():\n",
    "    if key not in ['numerical_features', 'categorical_features', 'preprocessing_steps', 'feature_names']:\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# Test predictions on new data\n",
    "sample_predictions = loaded_pipeline.predict_proba(X_test[:5])[:, 1]\n",
    "print(f\"\\nüéØ Sample predictions on test data:\")\n",
    "for i, (pred, actual) in enumerate(zip(sample_predictions, y_test[:5])):\n",
    "    print(f\"  Sample {i+1}: Predicted probability = {pred:.3f}, Actual = {actual}\")\n",
    "\n",
    "# Create a production-ready prediction function\n",
    "def predict_survival(passenger_data, pipeline_path, metadata_path):\n",
    "    \"\"\"\n",
    "    Production-ready prediction function.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    passenger_data : dict or DataFrame\n",
    "        Passenger information\n",
    "    pipeline_path : str\n",
    "        Path to saved pipeline\n",
    "    metadata_path : str\n",
    "        Path to model metadata\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Prediction results\n",
    "    \"\"\"\n",
    "    # Load pipeline and metadata\n",
    "    pipeline = joblib.load(pipeline_path)\n",
    "    with open(metadata_path, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "    \n",
    "    # Convert to DataFrame if necessary\n",
    "    if isinstance(passenger_data, dict):\n",
    "        passenger_data = pd.DataFrame([passenger_data])\n",
    "    \n",
    "    # Make prediction\n",
    "    survival_prob = pipeline.predict_proba(passenger_data)[:, 1][0]\n",
    "    survival_prediction = pipeline.predict(passenger_data)[0]\n",
    "    \n",
    "    return {\n",
    "        'survival_probability': float(survival_prob),\n",
    "        'predicted_survival': bool(int(survival_prediction)),\n",
    "        'model_version': metadata['created_at'],\n",
    "        'model_performance': {\n",
    "            'train_auc': metadata['train_auc'],\n",
    "            'test_auc': metadata['test_auc']\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "example_passenger = {\n",
    "    'pclass': 1,\n",
    "    'sex': 'female',\n",
    "    'age': 25,\n",
    "    'sibsp': 0,\n",
    "    'parch': 1,\n",
    "    'fare': 100.0,\n",
    "    'embarked': 'S',\n",
    "    'cabin': None\n",
    "}\n",
    "\n",
    "prediction_result = predict_survival(\n",
    "    example_passenger,\n",
    "    os.path.join(model_dir, model_filename),\n",
    "    os.path.join(model_dir, metadata_filename)\n",
    ")\n",
    "\n",
    "print(f\"\\nüé≠ Example prediction for passenger:\")\n",
    "print(f\"  Input: {example_passenger}\")\n",
    "print(f\"  Prediction: {prediction_result}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Pipeline persistence and versioning complete!\")\n",
    "print(f\"üìÅ Models saved in: {model_dir}/\")\n",
    "print(f\"üîß Ready for production deployment!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f8963d",
   "metadata": {},
   "source": [
    "## üéØ Summary and Best Practices\n",
    "\n",
    "### ‚úÖ What We've Accomplished\n",
    "\n",
    "1. **üîß Automated Pipelines**: Created reproducible preprocessing pipelines using `ColumnTransformer` and `Pipeline`\n",
    "2. **üîç Outlier Management**: Implemented detection and treatment strategies for data quality\n",
    "3. **üìä Robust Evaluation**: Used cross-validation to assess pipeline performance reliably\n",
    "4. **üéØ Feature Analysis**: Analyzed feature importance to understand model decisions\n",
    "5. **üìà Experiment Tracking**: Logged experiments with MLflow for reproducibility\n",
    "6. **üíæ Production Ready**: Saved versioned models with metadata for deployment\n",
    "\n",
    "### üöÄ Production Best Practices\n",
    "\n",
    "1. **Pipeline Everything**: Always use `Pipeline` objects to prevent data leakage\n",
    "2. **Version Control**: Track model versions, parameters, and performance metrics\n",
    "3. **Monitoring**: Implement data drift detection in production\n",
    "4. **Testing**: Create unit tests for preprocessing functions\n",
    "5. **Documentation**: Maintain clear documentation of preprocessing decisions\n",
    "6. **Rollback Strategy**: Keep previous model versions for quick rollback\n",
    "\n",
    "### üìö Additional Resources\n",
    "\n",
    "- **MLflow Documentation**: [https://mlflow.org/docs/latest/index.html](https://mlflow.org/docs/latest/index.html)\n",
    "- **Scikit-learn Pipelines**: [https://scikit-learn.org/stable/modules/compose.html](https://scikit-learn.org/stable/modules/compose.html)\n",
    "- **Data Validation with Great Expectations**: [https://greatexpectations.io/](https://greatexpectations.io/)\n",
    "- **Model Deployment with FastAPI**: [https://fastapi.tiangolo.com/](https://fastapi.tiangolo.com/)\n",
    "\n",
    "### üéì Next Steps\n",
    "\n",
    "1. Implement automated hyperparameter tuning with `Optuna` or `Hyperopt`\n",
    "2. Add data validation checks with `Great Expectations`\n",
    "3. Create a REST API for model serving with `FastAPI`\n",
    "4. Set up CI/CD pipelines for automated model training and deployment\n",
    "5. Implement monitoring dashboards for model performance in production\n",
    "\n",
    "**üéâ Congratulations! You now have the tools to build production-ready ML preprocessing pipelines!**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
