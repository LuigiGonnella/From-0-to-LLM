{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiCXg8ZToNM1",
        "outputId": "4d9c4fe1-1103-46ca-f4ae-47b7f6fdf901"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.8.0+cu126\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNDx_auNoilR",
        "outputId": "3db5d36a-7420-40bd-f5bb-263a539a0e3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Sep 21 09:40:35 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   57C    P0             27W /   70W |     124MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "MFs4N3yrooFh"
      },
      "outputs": [],
      "source": [
        "t = torch.rand(356, 64, 64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2MZN_XEospc",
        "outputId": "8a6ca18d-7343-4c2b-ce97-3eb47af26e4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([356, 64, 64])\n",
            "(356, 64, 64)\n"
          ]
        }
      ],
      "source": [
        "t_torch = torch.rand(356, 64, 64)\n",
        "print(t_torch.size())\n",
        "\n",
        "t_np = t_torch.numpy()\n",
        "print(t_np.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "i28yywZwo0xI"
      },
      "outputs": [],
      "source": [
        "t = t.cuda() #moving the tensor t to GPU:0 (we can have more GPUs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ynkfDH_Oo8IC"
      },
      "outputs": [],
      "source": [
        "t1 = torch.rand(356, 64, 64) #same shape of t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "-lGlAQFno_qk",
        "outputId": "944d591f-d818-4a78-c375-bbed6eef995f"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-155672930.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;31m#fails because all tensors must be to the sampe hardware (CPU or GPU)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
          ]
        }
      ],
      "source": [
        "t2 = t + t1 #fails because all tensors must be to the sampe hardware (CPU or GPU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5J9UwsEpc90",
        "outputId": "420a90fb-b550-464d-9f08-0155abcae7e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "random array: \n",
            " [[0.46927862 0.93788905 0.70780517]\n",
            " [0.85295074 0.93868899 0.55339853]\n",
            " [0.96630035 0.90333889 0.74412538]\n",
            " [0.67295907 0.42939896 0.55267707]\n",
            " [0.42328624 0.59648679 0.84939562]\n",
            " [0.45683561 0.14777844 0.24625424]] \n",
            "\n",
            "zeros array: \n",
            " [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]] \n",
            "\n",
            "ones array: \n",
            " [[1. 1. 1.]\n",
            " [1. 1. 1.]\n",
            " [1. 1. 1.]\n",
            " [1. 1. 1.]\n",
            " [1. 1. 1.]\n",
            " [1. 1. 1.]] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "#NUMPY ARRAYS, we can do the same\n",
        "\n",
        "arr1 = np.random.random((6,3))\n",
        "print(f'random array: \\n {arr1} \\n')\n",
        "\n",
        "arr2 = np.zeros((6,3), dtype = np.float32)\n",
        "print(f'zeros array: \\n {arr2} \\n')\n",
        "\n",
        "arr3 = np.ones((6,3), dtype = np.float32)\n",
        "print(f'ones array: \\n {arr3} \\n')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQD8qbKrqC3n",
        "outputId": "e705a905-04c3-4f02-c47b-91eb669114e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([6, 3])\n",
            "torch.float64\n",
            "cpu\n"
          ]
        }
      ],
      "source": [
        "#convert from numpy to torch\n",
        "\n",
        "tensor = torch.from_numpy(arr1) #moved to tensor torch so now it can be moved to GPU\n",
        "print(tensor.size())\n",
        "print(tensor.dtype)\n",
        "print(tensor.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFmkCID3qQU-",
        "outputId": "0cf18cec-15dd-41ff-cd4b-f4cd3e12fdb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.46927862 0.93788905 0.70780517]\n",
            " [0.85295074 0.93868899 0.55339853]\n",
            " [0.96630035 0.90333889 0.74412538]\n",
            " [0.67295907 0.42939896 0.55267707]\n",
            " [0.42328624 0.59648679 0.84939562]\n",
            " [0.45683561 0.14777844 0.24625424]]\n",
            "tensor([[0.4693, 0.9379, 0.7078],\n",
            "        [0.8530, 0.9387, 0.5534],\n",
            "        [0.9663, 0.9033, 0.7441],\n",
            "        [0.6730, 0.4294, 0.5527],\n",
            "        [0.4233, 0.5965, 0.8494],\n",
            "        [0.4568, 0.1478, 0.2463]], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "#from tensor to numpy\n",
        "arr1 = tensor.numpy()\n",
        "print(arr1)\n",
        "print(tensor)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llj9HX8SrcU_"
      },
      "source": [
        "# How to train a neural network\n",
        "\n",
        "we basically have to do 4 steps and repeat untile we converge\n",
        "\n",
        "1) FROWARD PASS: we feed an input into the network and see its predictions --> array of probabilities, one for each class. Then we take the major one and see the result\n",
        "\n",
        "2) COMPUTE LOSS: we compare the outcome with the ground truth with a loss function\n",
        "\n",
        "3) BACKWARD PASS: Chan Rule to compute the gradient of the loss in respect to the parameters (PYTORCH AUTOGRAD)\n",
        "\n",
        "4) UPDATE PARAMETERS: we update the parameters as the opposite of the gradient in that direction, with a given learning rate (PYTORCH OPTIMIZER)\n",
        "\n",
        "--> REPEAT FROM 1 UNTIL CONVERGE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcpWQsWfs0nd"
      },
      "source": [
        "# Computational graph\n",
        "During the training, the network changes because at each step we update its parameters, so we have to keep track of these changes looking at the computational graph (e. g. Full Connected Layer --> TANH --> ...), and this is managed automaticcaly by AUTOGRAD\n",
        "\n",
        "# Basic Components to train a Network\n",
        "\n",
        "1) DEFINE THE NETWORK ARCHITECTURE\n",
        "A subclass of torch.nn.Module\n",
        "\n",
        "2) DEFINE A DATASET\n",
        "A subclass of torch.utils.data.Dataset\n",
        "\n",
        "3) DEFINE LOSS FUNCTION and OPTIMIZER\n",
        "Define network prediction penalization (rergularization) and how to update parametres (learning rate, momentum exc..)\n",
        "\n",
        "4) DEFINE THE TRAINING LOOP\n",
        "Sort of main function interconnecting all components of the nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-m36MiCqxcL"
      },
      "outputs": [],
      "source": [
        "#DEFINE A SIMPLE MLP\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "#Fully connected nn with 1 hidden layer\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes): #define architecture of nn\n",
        "    super().__init__() #stiamo estendendo nn.Module\n",
        "    self.fc1 =  nn.Linear(input_size, hidden_size) #input size = #features, mentre hidden_size = #neurons\n",
        "    self.relu = nn.ReLU() #define activation\n",
        "    self.fc2 =  nn.Linear(hidden_size, num_classes) #ora il numero di features in input sono hidden_size usciti da prima\n",
        "    #essendo l'output layer, ho tanti neuroni quante classi e caccio probabilita per ogni classe\n",
        "\n",
        "    def forward(self, x): #define forward pass\n",
        "      h = self.fc1(x) #compute intermediate output h\n",
        "      h_act = self.relu(h) #relu\n",
        "      out = self.fc2(h_act) #output\n",
        "      return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4ltwYX_w8OL",
        "outputId": "b811ff8b-5503-4a0b-b68f-c451a5e262cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "my model: NeuralNetwork(\n",
            "  (fc1): Linear(in_features=784, out_features=500, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# CONNECT nn TO INPUTS\n",
        "\n",
        "input_size, hidden_size, num_classes = 784, 500, 10\n",
        "model = NeuralNetwork(input_size, hidden_size, num_classes)\n",
        "print(f'my model: {model}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4c7Jl0RxRoD"
      },
      "outputs": [],
      "source": [
        "# pass input to model for FORWARD PASS\n",
        "\n",
        "img = torch.tensor([[[48, 80, 79],\n",
        "                   [127, 111, 129],\n",
        "                   [118, 130, 139],\n",
        "                   [148, 110, 119]]]) #rgb image, must have 784 features, so for a FCL when we flat this img to 1xD tensor it must be 1x784\n",
        "\n",
        "res = model(img) #gives forward pass results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SF72qjuXyASg"
      },
      "source": [
        "# DATA PREPROCESSING\n",
        "we need a batch of images on which work with our nn, so we need\n",
        "1) DEFINE PREPROCESSING\n",
        "2) CREATE DATSET CLASS (bunch of images)\n",
        "3) CHOOSE SAMPLING STRATEGY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVyvNumyx-a5"
      },
      "outputs": [],
      "source": [
        "# DEFINE DATASET\n",
        "\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "\n",
        "class DatasetMNIST(Dataset):\n",
        "  def __init__(self, file_path, transform = None):\n",
        "    self.data = pd.read_csv(file_path)\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self): #mandatory to override\n",
        "    return len(self.data) #return all data\n",
        "\n",
        "  def __getitem__(self, index): #mandatory to override\n",
        "    image = self.data.iloc[index, 1:].values.astype(np.uint8).reshape(1, 28, 28) #PYTORCH usa convenzione channel first per motivi di efficienza\n",
        "    label = self.data.iloc[index, 0]\n",
        "\n",
        "    if self.transform is not None:\n",
        "      image = self.transform(image) #execute all preprocessing pipeline\n",
        "\n",
        "    return image, label\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.transforms.RandomHorizontalFlip(0.5),\n",
        "    transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "train_dataset = DatasetMNIST(file_path='.../input/train.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcR6OUN92gPP"
      },
      "source": [
        "But when we execute the training, we would to do it on a batch of images and not only on one, so we use DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwVjd93k2tPp"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
        "                               transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
        "                               ])),\n",
        "    batch_size = batch_size_train, shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwoInvYh3vJd"
      },
      "source": [
        "# LOSS\n",
        "extends torch.nn class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVfx4f444Lxc"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss() #example for classification problems\n",
        "\n",
        "pred = torch.rand(3, 5, requires_grad=True) #3 samples classificati con probabilita p_i in ognuna delle 5 classi c_i\n",
        "ground_truth = torch.empty(3, dtype=torch.long).random_(5) #3 numeri casuali da 0 a 5\n",
        "\n",
        "loss = loss_fn(pred, ground_truth)\n",
        "\n",
        "loss.backward() #compute gradients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFlHg5Fc50-N"
      },
      "source": [
        "# OPTIMIZER\n",
        "Now we need to update the parameters after cmputing the backward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "belY0vjW5uyx"
      },
      "outputs": [],
      "source": [
        "from torch import optim\n",
        "#we pass at least parameters + learning rate as basic parameter to the optimizer\n",
        "\n",
        "#STOCHSTIC GRADIENT DESCENT\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9) #momentum=lambda in the formula of momentum\n",
        "\n",
        "#ADAPTIVE MOMENT ESTIMATION\n",
        "optimizer = optim.Adam([var1, var2], lr=0.0001)\n",
        "\n",
        "#function\n",
        "optimizer.step() # --> it is updating parameters\n",
        "\n",
        "\n",
        "#FULL FLOW\n",
        "def flow(dataset):\n",
        "  for input, target in dataset:\n",
        "    optimizer.zero_grad() #reset gradient\n",
        "    pred = model(input) #prediction after forware pass\n",
        "    loss = loss_fn(pred, target) #calculate loss\n",
        "    loss.backward() #compute gradients for each parameter\n",
        "    optimizer.step() #update parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HydnKb4s-kqr"
      },
      "source": [
        "#TRAINING A NEURAL NETWROK\n",
        "We train NN in epochs, an epoch is a full iteration on the dataset, so for example if we have 1000 images, divided in 10 batches of 100 images, when we have given all 10 batches to the model the first time we have completed the first epoch.\n",
        "\n",
        "Considering that ther isn't a clear stop point to te training phase (usually for complex nn it is impossible to reach a minimum in loss function) we can decide a number of epochs for the training and iterate over them.\n",
        "\n",
        "A better option is to use a validation set to compute the errors at each epoch and stop training when this error doesn't improve.\n",
        "\n",
        "Other options can be: learning rate scheduling --> decrease learning rate gradually to get close to the minimum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPav1kJGAj9p"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss() #IMPORTANT --> as we have seen in thery, this loss function is thought for multiclass classification problems, so it has a softmax inside\n",
        "#that make all the outputs sum up to 1 like probabilities should do, so we don't have to worry about normilize outputs with this loss\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "# IF WE WANT TO TRAIN ON GPU:\n",
        "# model = model.cuda()\n",
        "for epoch in range(100):\n",
        "  tot_loss, tot_samples = 0.0, 0\n",
        "  for i, data in enumerate(train_dataloader):\n",
        "    inputs, labels = data\n",
        "    tot_samples += inputs.size(0)\n",
        "\n",
        "    # IF WE WANT TO TRAIN ON GPU:\n",
        "    # inputs = inputs.cuda()\n",
        "    # labels = labels.cuda()\n",
        "    #! --> thi is possible because we don't transfer all dataset on GPU, but only one batch at a time\n",
        "    #\n",
        "    #\n",
        "\n",
        "    #zeroing the gradients of weights, otherwise gradients of different batches will sum\n",
        "    optimizer.zero_grad() #after backward, the value of layer.weights.grad will bel != 0 and this is nopt good for next gradients calculation\n",
        "    preds = model(inputs) #all batch of inputs\n",
        "    loss = criterion(preds, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    tot_loss += loss.item() * inputs.size(0) #.item() converte loss in un numero\n",
        "    #questo numero e la media del loss rispetto al batch, quindi moltiplicando per il batch_size otteniamo il loss totale del batch\n",
        "    #infatti noi stiamno mandando nel modello non un input, ma tanti input insieme (inputs_size), quidi ci saranno inputs_size NN parallele che calcoleranno\n",
        "    #la cross entropy, es. inputs_size = 10 --> 10 numeri di loss, quindi loss_item() prende la media\n",
        "\n",
        "  #end of epoch, calculate avergae loss for sample (in entire dataset)\n",
        "  print(f'Epoch {epoch} average loss for sample is: {(tot_loss*1.0/float(tot_samples)):.6f}') #to see when we converge if there is a plateau across the epochs"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
